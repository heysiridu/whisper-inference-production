import pathlib
import os
import typing
import bentoml
import warnings
import logging
import time

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

LANGUAGE_CODE = "en"

with bentoml.importing():
    import whisperx
    import torch

@bentoml.service(
    traffic={"timeout": 300},  # å¢åŠ è¶…æ—¶æ—¶é—´å¤„ç†é•¿éŸ³é¢‘
    resources={"gpu": 1, "memory": "12Gi"},  # å¢åŠ å†…å­˜
    image=bentoml.images.PythonImage(python_version="3.11")
    .system_packages("ffmpeg")
    .system_packages("libsndfile1-dev")
    # å…¼å®¹æ€§ä¿®å¤ï¼šä½¿ç”¨ç¨³å®šç‰ˆæœ¬ç»„åˆ
    .python_packages("torch==2.1.2")
    .python_packages("torchaudio==2.1.2")
    .python_packages("transformers==4.35.2")
    .python_packages("faster-whisper==0.10.1")
    .python_packages("whisperx==3.1.1")
    .python_packages("pyannote.audio==3.1.1")
    .python_packages("pyannote.core==5.0.0")
    .python_packages("librosa==0.10.1")
    .python_packages("soundfile==0.12.1")
    .python_packages("bentoml>=1.2.0"),
)
class WhisperX:
    """
    Enhanced WhisperX service based on the original implementation
    Source: https://github.com/m-bain/whisperX
    
    Improvements:
    - Fixed CUDA/PyTorch/pyannote compatibility issues
    - Enhanced error handling and recovery
    - Better segments processing and formatting
    - Intelligent device detection
    - Graceful fallback strategies
    """
    
    def __init__(self):
        """åˆå§‹åŒ– WhisperX æœåŠ¡"""
        # å…¼å®¹æ€§è®¾ç½®
        self._setup_compatibility()
        
        # æ™ºèƒ½è®¾å¤‡æ£€æµ‹
        self._detect_device()
        
        # æ¨¡å‹åŠ è½½
        self._load_models()
        
        logger.info("ğŸ‰ WhisperX æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_compatibility(self):
        """è®¾ç½®å…¼å®¹æ€§ç¯å¢ƒ"""
        # å¿½ç•¥ç‰ˆæœ¬å…¼å®¹æ€§è­¦å‘Š
        warnings.filterwarnings("ignore", message=".*pyannote.*")
        warnings.filterwarnings("ignore", message=".*torch.*")
        warnings.filterwarnings("ignore", message=".*TensorFloat-32.*")
        
        # PyTorch å…¼å®¹æ€§è®¾ç½®
        if torch.cuda.is_available():
            torch.backends.cuda.matmul.allow_tf32 = False
            torch.backends.cudnn.allow_tf32 = False
            torch.cuda.empty_cache()
        
        logger.info("âœ… å…¼å®¹æ€§ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    def _detect_device(self):
        """æ™ºèƒ½è®¾å¤‡æ£€æµ‹å’Œé…ç½®"""
        if torch.cuda.is_available():
            self.device = "cuda"
            compute_type = "int8"  # æ›´ç¨³å®šçš„ç²¾åº¦
            self.batch_size = 8    # ä¿å®ˆçš„æ‰¹å¤§å°
            gpu_name = torch.cuda.get_device_name(0)
            logger.info(f"ğŸš€ ä½¿ç”¨ CUDA: {gpu_name}")
            
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            self.device = "mps"
            compute_type = "int8"
            self.batch_size = 4
            logger.info("ğŸ ä½¿ç”¨ Apple MPS")
            
        else:
            self.device = "cpu"
            compute_type = "int8"
            self.batch_size = 4  # åŸç‰ˆæ˜¯16ï¼Œä½†ä¸ºäº†å…¼å®¹æ€§é™ä½
            logger.info("ğŸ’» ä½¿ç”¨ CPU")
        
        self.compute_type = compute_type
        logger.info(f"ğŸ“Š è®¾å¤‡é…ç½®: {self.device}, ç²¾åº¦: {compute_type}, æ‰¹å¤§å°: {self.batch_size}")
    
    def _load_models(self):
        """åŠ è½½æ¨¡å‹ï¼ˆä¿æŒåŸç‰ˆé€»è¾‘ï¼Œå¢åŠ å®¹é”™ï¼‰"""
        try:
            # ä¸»æ¨¡å‹åŠ è½½ - ä¸åŸç‰ˆé€»è¾‘ä¸€è‡´
            logger.info("ğŸ”„ åŠ è½½ Whisper æ¨¡å‹...")
            self.model = whisperx.load_model(
                "large-v2", 
                self.device, 
                compute_type=self.compute_type, 
                language=LANGUAGE_CODE
            )
            logger.info("âœ… Whisper æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ large-v2 æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.info("ğŸ”„ å°è¯•åŠ è½½ medium æ¨¡å‹...")
            try:
                self.model = whisperx.load_model(
                    "medium", 
                    self.device, 
                    compute_type=self.compute_type, 
                    language=LANGUAGE_CODE
                )
                logger.info("âœ… medium æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e2:
                logger.warning(f"âš ï¸ medium æ¨¡å‹ä¹Ÿå¤±è´¥: {e2}")
                logger.info("ğŸ”„ ä½¿ç”¨ base æ¨¡å‹ä½œä¸ºæœ€åå¤‡é€‰...")
                self.model = whisperx.load_model(
                    "base", 
                    self.device, 
                    compute_type=self.compute_type, 
                    language=LANGUAGE_CODE
                )
                logger.info("âœ… base æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # å¯¹é½æ¨¡å‹åŠ è½½ - ä¸åŸç‰ˆé€»è¾‘ä¸€è‡´ï¼Œå¢åŠ å®¹é”™
        try:
            logger.info("ğŸ”„ åŠ è½½å¯¹é½æ¨¡å‹...")
            self.model_a, self.metadata = whisperx.load_align_model(
                language_code=LANGUAGE_CODE, 
                device=self.device
            )
            self.alignment_enabled = True
            logger.info("âœ… å¯¹é½æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.info("ğŸ“ ç»§ç»­ä½¿ç”¨åŸºç¡€è½¬å½•åŠŸèƒ½")
            self.model_a = None
            self.metadata = None
            self.alignment_enabled = False
    
    def _process_segments(self, segments):
        """å¢å¼ºçš„ segments å¤„ç†"""
        if not segments:
            return []
        
        processed_segments = []
        for i, segment in enumerate(segments):
            # åŸºç¡€ä¿¡æ¯ï¼ˆä¿æŒåŸç‰ˆæ ¼å¼ï¼‰
            processed_segment = {
                "id": i,
                "start": segment.get("start", 0.0),
                "end": segment.get("end", 0.0),
                "text": segment.get("text", "").strip(),
            }
            
            # å¦‚æœæœ‰è¯çº§å¯¹é½ä¿¡æ¯ï¼Œæ·»åŠ åˆ° segment ä¸­
            if "words" in segment:
                processed_segment["words"] = segment["words"]
                
                # è®¡ç®—é¢å¤–ç»Ÿè®¡ä¿¡æ¯
                words = segment["words"]
                if words:
                    processed_segment["word_count"] = len(words)
                    processed_segment["confidence"] = sum(
                        word.get("score", 0) for word in words if "score" in word
                    ) / len(words) if any("score" in word for word in words) else None
            
            # è®¡ç®—æ®µè½æ—¶é•¿
            duration = processed_segment["end"] - processed_segment["start"]
            processed_segment["duration"] = round(duration, 2)
            
            # ä¼°ç®—è¯­é€Ÿï¼ˆæ¯åˆ†é’Ÿå•è¯æ•°ï¼‰
            word_count = len(processed_segment["text"].split())
            if duration > 0:
                wpm = (word_count / duration) * 60
                processed_segment["words_per_minute"] = round(wpm, 1)
            
            processed_segments.append(processed_segment)
        
        return processed_segments
    
    def _generate_summary_stats(self, result, processing_time):
        """ç”Ÿæˆè½¬å½•ç»Ÿè®¡æ‘˜è¦"""
        segments = result.get("segments", [])
        
        if not segments:
            return {
                "total_segments": 0,
                "total_duration": 0,
                "total_words": 0,
                "processing_time": processing_time
            }
        
        # è®¡ç®—æ€»æ—¶é•¿
        total_duration = max(seg.get("end", 0) for seg in segments) if segments else 0
        
        # è®¡ç®—æ€»å•è¯æ•°
        total_words = sum(len(seg.get("text", "").split()) for seg in segments)
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        confidences = []
        for seg in segments:
            if "words" in seg:
                for word in seg["words"]:
                    if "score" in word:
                        confidences.append(word["score"])
        
        avg_confidence = sum(confidences) / len(confidences) if confidences else None
        
        # è®¡ç®—å¤„ç†é€Ÿåº¦æ¯”ç‡
        speed_ratio = total_duration / processing_time if processing_time > 0 else 0
        
        return {
            "total_segments": len(segments),
            "total_duration": round(total_duration, 2),
            "total_words": total_words,
            "average_confidence": round(avg_confidence, 3) if avg_confidence else None,
            "processing_time": round(processing_time, 2),
            "speed_ratio": round(speed_ratio, 1),  # ä¾‹å¦‚: 10x è¡¨ç¤ºå¤„ç†é€Ÿåº¦æ˜¯å®æ—¶æ’­æ”¾çš„10å€
            "alignment_enabled": self.alignment_enabled
        }
    
    @bentoml.api
    def transcribe(self, audio_file: pathlib.Path) -> typing.Dict[str, typing.Any]:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶ - ä¿æŒåŸç‰ˆæ¥å£ï¼Œå¢å¼ºåŠŸèƒ½
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬å½•ç»“æœå­—å…¸ï¼ŒåŒ…å« segments å’Œç»Ÿè®¡ä¿¡æ¯
        """
        start_time = time.time()
        
        try:
            logger.info(f"ğŸµ å¼€å§‹è½¬å½•: {audio_file}")
            
            # åŠ è½½éŸ³é¢‘ - ä¸åŸç‰ˆä¸€è‡´
            audio = whisperx.load_audio(audio_file)
            
            # è½¬å½• - ä¸åŸç‰ˆä¸€è‡´
            result = self.model.transcribe(audio, batch_size=self.batch_size)
            
            # å¯¹é½å¤„ç† - ä¸åŸç‰ˆé€»è¾‘ä¸€è‡´ï¼Œå¢åŠ å®¹é”™
            if self.alignment_enabled and self.model_a is not None:
                try:
                    result = whisperx.align(
                        result["segments"], 
                        self.model_a, 
                        self.metadata, 
                        audio, 
                        self.device, 
                        return_char_alignments=False
                    )
                    logger.info("âœ… è¯çº§å¯¹é½å®Œæˆ")
                except Exception as e:
                    logger.warning(f"âš ï¸ å¯¹é½å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€è½¬å½•: {e}")
                    # ç»§ç»­ä½¿ç”¨åŸå§‹ç»“æœ
            
            # å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # å¢å¼ºçš„ segments å¤„ç†
            if "segments" in result:
                result["segments"] = self._process_segments(result["segments"])
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
            result["stats"] = self._generate_summary_stats(result, processing_time)
            
            # æ·»åŠ æœåŠ¡ä¿¡æ¯ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
            result["service_info"] = {
                "device": self.device,
                "compute_type": self.compute_type,
                "batch_size": self.batch_size,
                "alignment_enabled": self.alignment_enabled
            }
            
            logger.info(f"âœ… è½¬å½•å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}s")
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            logger.error(f"âŒ è½¬å½•å¤±è´¥: {e}")
            
            # è¿”å›é”™è¯¯ä¿¡æ¯ï¼ˆä¿æŒæ¥å£ä¸€è‡´æ€§ï¼‰
            return {
                "segments": [],
                "text": "",
                "language": LANGUAGE_CODE,
                "error": str(e),
                "stats": {
                    "processing_time": processing_time,
                    "status": "failed"
                }
            }
    
    @bentoml.api
    def health_check(self) -> typing.Dict[str, typing.Any]:
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ˆæ–°å¢ï¼‰"""
        return {
            "status": "healthy",
            "device": self.device,
            "compute_type": self.compute_type,
            "batch_size": self.batch_size,
            "alignment_enabled": self.alignment_enabled,
            "cuda_available": torch.cuda.is_available(),
            "mps_available": (
                torch.backends.mps.is_available() 
                if hasattr(torch.backends, 'mps') else False
            )
        }
